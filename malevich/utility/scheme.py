# generated by datamodel-codegen:
#   filename:  tmpdwclmpqz.json
#   timestamp: 2024-07-16T13:47:53+00:00




from typing import Any, Optional

from malevich.models._model import _Model
from pydantic import Field


class AddColumn(_Model):
    column: Optional[str] = Field(
        'new_column', description='The name of the new column', title='Column'
    )
    value: Any = Field(
        'new_value', description='The value of the new column', title='Value'
    )
    position: Optional[int] = Field(
        0,
        description='The position to insert the new column. If positive, the new column will be inserted from the beginning of the dataframe. If negative, the new column will be inserted from the end of the dataframe',
        title='Position',
    )
    skip_if_exists: Optional[bool] = Field(
        False,
        description='If set, the processor will not raise exeception if column exists.',
        title='Skip If Exists',
    )

# generated by datamodel-codegen:
#   filename:  tmpk9wp5pa1.json
#   timestamp: 2024-07-16T13:47:53+00:00




from typing import Optional

from malevich.models._model import _Model
from pydantic import Field


class Download(_Model):
    prefix: Optional[str] = Field(
        '',
        description='A prefix to add to the paths of downloaded files. If not specified, files will be downloaded to the root of the app directory',
        title='Prefix',
    )

# generated by datamodel-codegen:
#   filename:  tmp4fis_9_5.json
#   timestamp: 2024-07-16T13:47:53+00:00




from typing import Optional

from malevich.models._model import _Model
from pydantic import Field


class GetLinksToFiles(_Model):
    expiration: Optional[int] = Field(
        21600,
        description='The number of seconds after which the link will expire. Defaults to 6 hours. Maximum is 24 hours',
        title='Expiration',
    )

# generated by datamodel-codegen:
#   filename:  tmp1b1t75s1.json
#   timestamp: 2024-07-16T13:47:53+00:00




from typing import Optional

from malevich.models._model import _Model
from pydantic import Field


class MatchPattern(_Model):
    pattern: str = Field(
        ..., description='A regular expression pattern to match', title='Pattern'
    )
    join_char: Optional[str] = Field(
        ';', description='A character to join the matches with', title='Join Char'
    )

# generated by datamodel-codegen:
#   filename:  tmpmx_cif4f.json
#   timestamp: 2024-07-16T13:47:53+00:00




from typing import List, Optional, Union

from malevich.models._model import _Model
from pydantic import Field


class Merge(_Model):
    how: Optional[str] = Field(
        'inner', description='The type of merge to be performed', title='How'
    )
    both_on: Optional[Union[str, List]] = Field(
        '',
        description="Column name or 'index' to merge on. If 'index', the index of the dataframe will be used. If column name, the column should be present in all dataframes",
        title='Both On',
    )
    left_on: Optional[Union[str, List]] = Field(
        '',
        description="Column name or 'index' to join on in the left DataFrame. If 'index', the index of the dataframe will be used. If column name, the column should be present in all but last dataframes",
        title='Left On',
    )
    right_on: Optional[Union[str, List]] = Field(
        '',
        description="Column name or 'index' to join on in the right DataFrame. If 'index', the index of the dataframe will be used. If column name, the column should be present in all but first dataframes",
        title='Right On',
    )
    suffixes: Optional[List] = Field(
        ['_0', '_1'],
        description='Suffix to apply to overlapping column names in the left and right dataframes',
        title='Suffixes',
    )

# generated by datamodel-codegen:
#   filename:  tmps9u_pal_.json
#   timestamp: 2024-07-16T13:47:53+00:00




from typing import List, Optional, Union

from malevich.models._model import _Model
from pydantic import Field


class S3Save(_Model):
    names: Union[List[str], str] = Field(
        ..., description='Names of the dataframes to be saved', title='Names'
    )
    append_run_id: Optional[bool] = Field(
        False,
        description='If True, the run_id is appended to the names of the dataframes',
        title='Append Run Id',
    )
    extra_str: Optional[str] = Field(
        None,
        description='If provided, it is appended to the names of the dataframes',
        title='Extra Str',
    )
    aws_access_key_id: str = Field(
        ..., description='AWS access key ID', title='Aws Access Key Id'
    )
    aws_secret_access_key: str = Field(
        ..., description='AWS secret access key', title='Aws Secret Access Key'
    )
    bucket_name: str = Field(
        ..., description='Name of the S3 bucket', title='Bucket Name'
    )
    endpoint_url: Optional[str] = Field(
        None, description='Endpoint URL of the S3 bucket', title='Endpoint Url'
    )
    aws_region: Optional[str] = Field(
        None, description='AWS region of the S3 bucket', title='Aws Region'
    )

# generated by datamodel-codegen:
#   filename:  tmpxjqi5_lm.json
#   timestamp: 2024-07-16T13:47:53+00:00




from typing import Optional

from malevich.models._model import _Model
from pydantic import Field


class S3SaveFilesAuto(_Model):
    append_run_id: Optional[bool] = Field(
        False,
        description='If True, the run_id is appended to the names of the files',
        title='Append Run Id',
    )
    extra_str: Optional[str] = Field(
        None,
        description='If provided, it is appended to the names of the files',
        title='Extra Str',
    )
    aws_access_key_id: str = Field(
        ..., description='AWS access key ID', title='Aws Access Key Id'
    )
    aws_secret_access_key: str = Field(
        ..., description='AWS secret access key', title='Aws Secret Access Key'
    )
    bucket_name: str = Field(
        ..., description='Name of the S3 bucket', title='Bucket Name'
    )
    endpoint_url: Optional[str] = Field(
        None, description='Endpoint URL of the S3 bucket', title='Endpoint Url'
    )
    aws_region: Optional[str] = Field(
        None, description='AWS region of the S3 bucket', title='Aws Region'
    )

# generated by datamodel-codegen:
#   filename:  tmp3aow_xet.json
#   timestamp: 2024-07-16T13:47:53+00:00




from typing import Optional

from malevich.models._model import _Model
from pydantic import Field


class S3SaveFiles(_Model):
    append_run_id: Optional[bool] = Field(
        False,
        description='If True, the run_id is appended to the names of the files',
        title='Append Run Id',
    )
    aws_access_key_id: str = Field(
        ..., description='AWS access key ID', title='Aws Access Key Id'
    )
    aws_secret_access_key: str = Field(
        ..., description='AWS secret access key', title='Aws Secret Access Key'
    )
    bucket_name: str = Field(
        ..., description='Name of the S3 bucket', title='Bucket Name'
    )
    endpoint_url: Optional[str] = Field(
        None, description='Endpoint URL of the S3 bucket', title='Endpoint Url'
    )
    aws_region: Optional[str] = Field(
        None, description='AWS region of the S3 bucket', title='Aws Region'
    )

# generated by datamodel-codegen:
#   filename:  tmpes9id5yx.json
#   timestamp: 2024-07-16T13:47:53+00:00




from typing import Optional

from malevich.models._model import _Model
from pydantic import Field


class S3DownloadFiles(_Model):
    aws_access_key_id: str = Field(
        ..., description='AWS access key ID', title='Aws Access Key Id'
    )
    aws_secret_access_key: str = Field(
        ..., description='AWS secret access key', title='Aws Secret Access Key'
    )
    bucket_name: str = Field(
        ..., description='Name of the S3 bucket', title='Bucket Name'
    )
    endpoint_url: Optional[str] = Field(
        None, description='Endpoint URL of the S3 bucket', title='Endpoint Url'
    )
    aws_region: Optional[str] = Field(
        None, description='AWS region of the S3 bucket', title='Aws Region'
    )

# generated by datamodel-codegen:
#   filename:  tmp15ub40jz.json
#   timestamp: 2024-07-16T13:47:53+00:00




from typing import Optional

from malevich.models._model import _Model
from pydantic import Field


class S3DownloadFilesAuto(_Model):
    aws_access_key_id: str = Field(
        ..., description='AWS access key ID', title='Aws Access Key Id'
    )
    aws_secret_access_key: str = Field(
        ..., description='AWS secret access key', title='Aws Secret Access Key'
    )
    bucket_name: str = Field(
        ..., description='Name of the S3 bucket', title='Bucket Name'
    )
    endpoint_url: Optional[str] = Field(
        None, description='Endpoint URL of the S3 bucket', title='Endpoint Url'
    )
    aws_region: Optional[str] = Field(
        None, description='AWS region of the S3 bucket', title='Aws Region'
    )

# generated by datamodel-codegen:
#   filename:  tmponk7ezfr.json
#   timestamp: 2024-07-16T13:47:53+00:00




from typing import Any, Dict, List, Optional

from malevich.models._model import _Model
from pydantic import Field


class Filter(_Model):
    conditions: Optional[List[Dict[str, Any]]] = Field(
        [],
        description='A list of conditions containing dictionaries',
        title='Conditions',
    )

# generated by datamodel-codegen:
#   filename:  tmpjbmpz_b7.json
#   timestamp: 2024-07-16T13:47:53+00:00




from typing import List, Optional

from malevich.models._model import _Model
from pydantic import Field


class Locs(_Model):
    column: Optional[str] = Field(
        None, description='The column to be extracted', title='Column'
    )
    columns: Optional[List[str]] = Field(
        None, description='The columns to be extracted', title='Columns'
    )
    column_idx: Optional[int] = Field(
        None, description='The column index to be extracted', title='Column Idx'
    )
    column_idxs: Optional[List[int]] = Field(
        None, description='The column indexes to be extracted', title='Column Idxs'
    )
    row: Optional[int] = Field(None, description='The row to be extracted', title='Row')
    rows: Optional[List[int]] = Field(
        None, description='The rows to be extracted', title='Rows'
    )
    row_idx: Optional[int] = Field(
        None, description='The row index to be extracted', title='Row Idx'
    )
    row_idxs: Optional[List[int]] = Field(
        None, description='The row indexes to be extracted', title='Row Idxs'
    )
    unique: Optional[bool] = Field(
        False,
        description='Get unique values from column. Must be used with `column` or `column_idx`',
        title='Unique',
    )

# generated by datamodel-codegen:
#   filename:  tmpfqswizz9.json
#   timestamp: 2024-07-16T13:47:53+00:00




from typing import Optional

from malevich.models._model import _Model
from pydantic import Field


class Subset(_Model):
    expr: Optional[str] = Field(
        None,
        description='A comma-separated list of integers or slices, e.g. `0,1:3,5:7,6,9:10`. The first dataframe has index 0',
        title='Expr',
    )

# generated by datamodel-codegen:
#   filename:  tmp1ybum9ff.json
#   timestamp: 2024-07-16T13:47:53+00:00




from typing import Optional

from malevich.models._model import _Model
from pydantic import Field


class SquashRows(_Model):
    by: Optional[str] = Field(
        'all',
        description='The column to group by. If not specified, all columns will be squashed',
        title='By',
    )
    delim: Optional[str] = Field(
        ',',
        description='The delimiter used to separate values in the columns. If not specified, the default delimiter is a comma (,)',
        title='Delim',
    )

# generated by datamodel-codegen:
#   filename:  tmp8c5svmtk.json
#   timestamp: 2024-07-16T13:47:53+00:00




from typing import Optional

from malevich.models._model import _Model
from pydantic import Field


class Squash(_Model):
    by: Optional[str] = Field(
        'all',
        description='The column to group by. If not specified, all columns will be squashed',
        title='By',
    )
    delim: Optional[str] = Field(
        ',',
        description='The delimiter used to separate values in the columns. If not specified, the default delimiter is a comma (,)',
        title='Delim',
    )

# generated by datamodel-codegen:
#   filename:  tmpxy48obfe.json
#   timestamp: 2024-07-16T13:47:53+00:00




from typing import List, Optional

from malevich.models._model import _Model
from pydantic import Field


class SquashColumns(_Model):
    columns: Optional[List[str]] = Field(
        None,
        description='The columns to squash. If not specified, all columns will be squashed',
        title='Columns',
    )
    result_column_name: Optional[str] = Field(
        None,
        description='The name of the resulting column. If not specified, the default name is the concatenation of the column names',
        title='Result Column Name',
    )
    drop: Optional[bool] = Field(
        False,
        description='Whether to drop the original columns. If not specified, the default value is False',
        title='Drop',
    )
    delim: Optional[str] = Field(
        ',',
        description='The delimiter used to separate values in the columns. If not specified, the default delimiter is a comma (,)',
        title='Delim',
    )

# generated by datamodel-codegen:
#   filename:  tmpo_ybubvw.json
#   timestamp: 2024-07-16T13:47:53+00:00




from typing import List, Optional

from malevich.models._model import _Model
from pydantic import Field


class Unwrap(_Model):
    columns: Optional[List[str]] = Field(
        ['all'],
        description='The columns to unwrap. If not specified, all columns will be unwrapped',
        title='Columns',
    )
    delimiter: Optional[str] = Field(
        ',',
        description='The delimiter used to separate values in the columns. If not specified, the default delimiter is a comma (,)',
        title='Delimiter',
    )

# generated by datamodel-codegen:
#   filename:  tmpzelp_8sf.json
#   timestamp: 2024-07-16T13:47:53+00:00




from typing import Any

from malevich.models._model import _Model
from pydantic import Field


class DefaultScheme(_Model):
    data: Any = Field(..., title='Data')

# generated by datamodel-codegen:
#   filename:  tmpaqt8ytn_.json
#   timestamp: 2024-07-16T13:47:53+00:00




from malevich.models._model import _Model
from pydantic import Field


class Obj(_Model):
    path: str = Field(..., title='Path')

# generated by datamodel-codegen:
#   filename:  tmpx1isaclb.json
#   timestamp: 2024-07-16T13:47:53+00:00




from typing import Any, Optional

from malevich.models._model import _Model
from pydantic import Field


class AddColumn(_Model):
    column: Optional[str] = Field(
        'new_column', description='The name of the new column', title='Column'
    )
    value: Any = Field(
        'new_value', description='The value of the new column', title='Value'
    )
    position: Optional[int] = Field(
        0,
        description='The position to insert the new column. If positive, the new column will be inserted from the beginning of the dataframe. If negative, the new column will be inserted from the end of the dataframe',
        title='Position',
    )
    skip_if_exists: Optional[bool] = Field(
        False,
        description='If set, the processor will not raise exeception if column exists.',
        title='Skip If Exists',
    )

# generated by datamodel-codegen:
#   filename:  tmp46jkl6a4.json
#   timestamp: 2024-07-16T13:47:53+00:00




from typing import Optional

from malevich.models._model import _Model
from pydantic import Field


class Download(_Model):
    prefix: Optional[str] = Field(
        '',
        description='A prefix to add to the paths of downloaded files. If not specified, files will be downloaded to the root of the app directory',
        title='Prefix',
    )

# generated by datamodel-codegen:
#   filename:  tmpcuf9in0z.json
#   timestamp: 2024-07-16T13:47:53+00:00




from malevich.models._model import _Model
from pydantic import Field


class Links(_Model):
    link: str = Field(..., title='Link')

# generated by datamodel-codegen:
#   filename:  tmp2rxgsufv.json
#   timestamp: 2024-07-16T13:47:53+00:00




from typing import Optional

from malevich.models._model import _Model
from pydantic import Field


class GetLinksToFiles(_Model):
    expiration: Optional[int] = Field(
        21600,
        description='The number of seconds after which the link will expire. Defaults to 6 hours. Maximum is 24 hours',
        title='Expiration',
    )

# generated by datamodel-codegen:
#   filename:  tmpxb3wl2i8.json
#   timestamp: 2024-07-16T13:47:53+00:00




from typing import Optional

from malevich.models._model import _Model
from pydantic import Field


class MatchPattern(_Model):
    pattern: str = Field(
        ..., description='A regular expression pattern to match', title='Pattern'
    )
    join_char: Optional[str] = Field(
        ';', description='A character to join the matches with', title='Join Char'
    )

# generated by datamodel-codegen:
#   filename:  tmpvqniic_u.json
#   timestamp: 2024-07-16T13:47:53+00:00




from typing import List, Optional, Union

from malevich.models._model import _Model
from pydantic import Field


class Merge(_Model):
    how: Optional[str] = Field(
        'inner', description='The type of merge to be performed', title='How'
    )
    both_on: Optional[Union[str, List]] = Field(
        '',
        description="Column name or 'index' to merge on. If 'index', the index of the dataframe will be used. If column name, the column should be present in all dataframes",
        title='Both On',
    )
    left_on: Optional[Union[str, List]] = Field(
        '',
        description="Column name or 'index' to join on in the left DataFrame. If 'index', the index of the dataframe will be used. If column name, the column should be present in all but last dataframes",
        title='Left On',
    )
    right_on: Optional[Union[str, List]] = Field(
        '',
        description="Column name or 'index' to join on in the right DataFrame. If 'index', the index of the dataframe will be used. If column name, the column should be present in all but first dataframes",
        title='Right On',
    )
    suffixes: Optional[List] = Field(
        ['_0', '_1'],
        description='Suffix to apply to overlapping column names in the left and right dataframes',
        title='Suffixes',
    )

# generated by datamodel-codegen:
#   filename:  tmp8soao5mx.json
#   timestamp: 2024-07-16T13:47:53+00:00




from typing import List, Optional, Union

from malevich.models._model import _Model
from pydantic import Field


class MergeThree(_Model):
    how: Optional[str] = Field(
        'inner', description='The type of merge to be performed', title='How'
    )
    both_on: Optional[Union[str, List]] = Field(
        '',
        description="Column name or 'index' to merge on. If 'index', the index of the dataframe will be used. If column name, the column should be present in all dataframes",
        title='Both On',
    )
    left_on: Optional[Union[str, List]] = Field(
        '',
        description="Column name or 'index' to join on in the left DataFrame. If 'index', the index of the dataframe will be used. If column name, the column should be present in all but last dataframes",
        title='Left On',
    )
    right_on: Optional[Union[str, List]] = Field(
        '',
        description="Column name or 'index' to join on in the right DataFrame. If 'index', the index of the dataframe will be used. If column name, the column should be present in all but first dataframes",
        title='Right On',
    )
    suffixes: Optional[List] = Field(
        ['_0', '_1'],
        description='Suffix to apply to overlapping column names in the left and right dataframes',
        title='Suffixes',
    )

# generated by datamodel-codegen:
#   filename:  tmp2bws04fl.json
#   timestamp: 2024-07-16T13:47:53+00:00




from typing import List, Optional, Union

from malevich.models._model import _Model
from pydantic import Field


class MergeTwo(_Model):
    how: Optional[str] = Field(
        'inner', description='The type of merge to be performed', title='How'
    )
    both_on: Optional[Union[str, List]] = Field(
        '',
        description="Column name or 'index' to merge on. If 'index', the index of the dataframe will be used. If column name, the column should be present in all dataframes",
        title='Both On',
    )
    left_on: Optional[Union[str, List]] = Field(
        '',
        description="Column name or 'index' to join on in the left DataFrame. If 'index', the index of the dataframe will be used. If column name, the column should be present in all but last dataframes",
        title='Left On',
    )
    right_on: Optional[Union[str, List]] = Field(
        '',
        description="Column name or 'index' to join on in the right DataFrame. If 'index', the index of the dataframe will be used. If column name, the column should be present in all but first dataframes",
        title='Right On',
    )
    suffixes: Optional[List] = Field(
        ['_0', '_1'],
        description='Suffix to apply to overlapping column names in the left and right dataframes',
        title='Suffixes',
    )

# generated by datamodel-codegen:
#   filename:  tmpw8ammu61.json
#   timestamp: 2024-07-16T13:47:53+00:00




from typing import List, Optional, Union

from malevich.models._model import _Model
from pydantic import Field


class S3Save(_Model):
    names: Union[List[str], str] = Field(
        ..., description='Names of the dataframes to be saved', title='Names'
    )
    append_run_id: Optional[bool] = Field(
        False,
        description='If True, the run_id is appended to the names of the dataframes',
        title='Append Run Id',
    )
    extra_str: Optional[str] = Field(
        None,
        description='If provided, it is appended to the names of the dataframes',
        title='Extra Str',
    )
    aws_access_key_id: str = Field(
        ..., description='AWS access key ID', title='Aws Access Key Id'
    )
    aws_secret_access_key: str = Field(
        ..., description='AWS secret access key', title='Aws Secret Access Key'
    )
    bucket_name: str = Field(
        ..., description='Name of the S3 bucket', title='Bucket Name'
    )
    endpoint_url: Optional[str] = Field(
        None, description='Endpoint URL of the S3 bucket', title='Endpoint Url'
    )
    aws_region: Optional[str] = Field(
        None, description='AWS region of the S3 bucket', title='Aws Region'
    )

# generated by datamodel-codegen:
#   filename:  tmpd3n6c2zl.json
#   timestamp: 2024-07-16T13:47:53+00:00




from typing import Optional

from malevich.models._model import _Model
from pydantic import Field


class S3SaveFilesAuto(_Model):
    append_run_id: Optional[bool] = Field(
        False,
        description='If True, the run_id is appended to the names of the files',
        title='Append Run Id',
    )
    extra_str: Optional[str] = Field(
        None,
        description='If provided, it is appended to the names of the files',
        title='Extra Str',
    )
    aws_access_key_id: str = Field(
        ..., description='AWS access key ID', title='Aws Access Key Id'
    )
    aws_secret_access_key: str = Field(
        ..., description='AWS secret access key', title='Aws Secret Access Key'
    )
    bucket_name: str = Field(
        ..., description='Name of the S3 bucket', title='Bucket Name'
    )
    endpoint_url: Optional[str] = Field(
        None, description='Endpoint URL of the S3 bucket', title='Endpoint Url'
    )
    aws_region: Optional[str] = Field(
        None, description='AWS region of the S3 bucket', title='Aws Region'
    )

# generated by datamodel-codegen:
#   filename:  tmpon0sh_cr.json
#   timestamp: 2024-07-16T13:47:53+00:00




from typing import Optional

from malevich.models._model import _Model
from pydantic import Field


class S3SaveFiles(_Model):
    append_run_id: Optional[bool] = Field(
        False,
        description='If True, the run_id is appended to the names of the files',
        title='Append Run Id',
    )
    aws_access_key_id: str = Field(
        ..., description='AWS access key ID', title='Aws Access Key Id'
    )
    aws_secret_access_key: str = Field(
        ..., description='AWS secret access key', title='Aws Secret Access Key'
    )
    bucket_name: str = Field(
        ..., description='Name of the S3 bucket', title='Bucket Name'
    )
    endpoint_url: Optional[str] = Field(
        None, description='Endpoint URL of the S3 bucket', title='Endpoint Url'
    )
    aws_region: Optional[str] = Field(
        None, description='AWS region of the S3 bucket', title='Aws Region'
    )

# generated by datamodel-codegen:
#   filename:  tmpib8zzff5.json
#   timestamp: 2024-07-16T13:47:53+00:00




from typing import Optional

from malevich.models._model import _Model
from pydantic import Field


class S3DownloadFiles(_Model):
    aws_access_key_id: str = Field(
        ..., description='AWS access key ID', title='Aws Access Key Id'
    )
    aws_secret_access_key: str = Field(
        ..., description='AWS secret access key', title='Aws Secret Access Key'
    )
    bucket_name: str = Field(
        ..., description='Name of the S3 bucket', title='Bucket Name'
    )
    endpoint_url: Optional[str] = Field(
        None, description='Endpoint URL of the S3 bucket', title='Endpoint Url'
    )
    aws_region: Optional[str] = Field(
        None, description='AWS region of the S3 bucket', title='Aws Region'
    )

# generated by datamodel-codegen:
#   filename:  tmppplhtsax.json
#   timestamp: 2024-07-16T13:47:53+00:00




from typing import Optional

from malevich.models._model import _Model
from pydantic import Field


class S3DownloadFilesAuto(_Model):
    aws_access_key_id: str = Field(
        ..., description='AWS access key ID', title='Aws Access Key Id'
    )
    aws_secret_access_key: str = Field(
        ..., description='AWS secret access key', title='Aws Secret Access Key'
    )
    bucket_name: str = Field(
        ..., description='Name of the S3 bucket', title='Bucket Name'
    )
    endpoint_url: Optional[str] = Field(
        None, description='Endpoint URL of the S3 bucket', title='Endpoint Url'
    )
    aws_region: Optional[str] = Field(
        None, description='AWS region of the S3 bucket', title='Aws Region'
    )

# generated by datamodel-codegen:
#   filename:  tmpwsh3l20y.json
#   timestamp: 2024-07-16T13:47:53+00:00




from malevich.models._model import _Model
from pydantic import Field


class FilenameS3Key(_Model):
    filename: str = Field(..., title='Filename')
    s3key: str = Field(..., title='S3Key')

# generated by datamodel-codegen:
#   filename:  tmp4aj1rzgw.json
#   timestamp: 2024-07-16T13:47:53+00:00




from malevich.models._model import _Model
from pydantic import Field


class S3Key(_Model):
    s3key: str = Field(..., title='S3Key')

# generated by datamodel-codegen:
#   filename:  tmp0_jm6rl3.json
#   timestamp: 2024-07-16T13:47:53+00:00




from malevich.models._model import _Model
from pydantic import Field


class Filename(_Model):
    filename: str = Field(..., title='Filename')

# generated by datamodel-codegen:
#   filename:  tmprrcyrg7o.json
#   timestamp: 2024-07-16T13:47:53+00:00




from typing import List, Optional

from malevich.models._model import _Model
from pydantic import Field


class Locs(_Model):
    column: Optional[str] = Field(
        None, description='The column to be extracted', title='Column'
    )
    columns: Optional[List[str]] = Field(
        None, description='The columns to be extracted', title='Columns'
    )
    column_idx: Optional[int] = Field(
        None, description='The column index to be extracted', title='Column Idx'
    )
    column_idxs: Optional[List[int]] = Field(
        None, description='The column indexes to be extracted', title='Column Idxs'
    )
    row: Optional[int] = Field(None, description='The row to be extracted', title='Row')
    rows: Optional[List[int]] = Field(
        None, description='The rows to be extracted', title='Rows'
    )
    row_idx: Optional[int] = Field(
        None, description='The row index to be extracted', title='Row Idx'
    )
    row_idxs: Optional[List[int]] = Field(
        None, description='The row indexes to be extracted', title='Row Idxs'
    )
    unique: Optional[bool] = Field(
        False,
        description='Get unique values from column. Must be used with `column` or `column_idx`',
        title='Unique',
    )

# generated by datamodel-codegen:
#   filename:  tmpjz1nau3r.json
#   timestamp: 2024-07-16T13:47:53+00:00




from typing import Optional

from malevich.models._model import _Model
from pydantic import Field


class Subset(_Model):
    expr: Optional[str] = Field(
        None,
        description='A comma-separated list of integers or slices, e.g. `0,1:3,5:7,6,9:10`. The first dataframe has index 0',
        title='Expr',
    )

# generated by datamodel-codegen:
#   filename:  tmpy6lsn58s.json
#   timestamp: 2024-07-16T13:47:53+00:00




from typing import Any, Dict, List, Optional

from malevich.models._model import _Model
from pydantic import Field


class Filter(_Model):
    conditions: Optional[List[Dict[str, Any]]] = Field(
        [],
        description='A list of conditions containing dictionaries',
        title='Conditions',
    )

# generated by datamodel-codegen:
#   filename:  tmph8v0xl84.json
#   timestamp: 2024-07-16T13:47:53+00:00




from typing import Optional

from malevich.models._model import _Model
from pydantic import Field


class SquashRows(_Model):
    by: Optional[str] = Field(
        'all',
        description='The column to group by. If not specified, all columns will be squashed',
        title='By',
    )
    delim: Optional[str] = Field(
        ',',
        description='The delimiter used to separate values in the columns. If not specified, the default delimiter is a comma (,)',
        title='Delim',
    )

# generated by datamodel-codegen:
#   filename:  tmp1kkzqrp2.json
#   timestamp: 2024-07-16T13:47:53+00:00




from typing import Optional

from malevich.models._model import _Model
from pydantic import Field


class Squash(_Model):
    by: Optional[str] = Field(
        'all',
        description='The column to group by. If not specified, all columns will be squashed',
        title='By',
    )
    delim: Optional[str] = Field(
        ',',
        description='The delimiter used to separate values in the columns. If not specified, the default delimiter is a comma (,)',
        title='Delim',
    )

# generated by datamodel-codegen:
#   filename:  tmpm5f7j54x.json
#   timestamp: 2024-07-16T13:47:54+00:00




from typing import List, Optional

from malevich.models._model import _Model
from pydantic import Field


class SquashColumns(_Model):
    columns: Optional[List[str]] = Field(
        None,
        description='The columns to squash. If not specified, all columns will be squashed',
        title='Columns',
    )
    result_column_name: Optional[str] = Field(
        None,
        description='The name of the resulting column. If not specified, the default name is the concatenation of the column names',
        title='Result Column Name',
    )
    drop: Optional[bool] = Field(
        False,
        description='Whether to drop the original columns. If not specified, the default value is False',
        title='Drop',
    )
    delim: Optional[str] = Field(
        ',',
        description='The delimiter used to separate values in the columns. If not specified, the default delimiter is a comma (,)',
        title='Delim',
    )

# generated by datamodel-codegen:
#   filename:  tmp0wfbeiw8.json
#   timestamp: 2024-07-16T13:47:54+00:00




from typing import List, Optional

from malevich.models._model import _Model
from pydantic import Field


class Unwrap(_Model):
    columns: Optional[List[str]] = Field(
        ['all'],
        description='The columns to unwrap. If not specified, all columns will be unwrapped',
        title='Columns',
    )
    delimiter: Optional[str] = Field(
        ',',
        description='The delimiter used to separate values in the columns. If not specified, the default delimiter is a comma (,)',
        title='Delimiter',
    )

